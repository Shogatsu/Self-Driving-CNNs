{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "try:\n",
    "    import _pickle as cPickle\n",
    "except:\n",
    "    import cPickle\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os, time, sys, math, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib notebook\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (16, 9)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(length):\n",
    "    initial = tf.constant(0.1, shape=[length], dtype=tf.float32)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createConvulationalLayer(input_data, channel_count, filter_size, filter_count, max_pooling=True):\n",
    "    shape = [filter_size, filter_size, channel_count, filter_count]\n",
    "    weights = weight_variable(shape=shape)\n",
    "    bias = bias_variable(length=filter_count)\n",
    "    layer = tf.nn.conv2d(input=input_data,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "    layer += bias\n",
    "    if max_pooling:\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "        layer = tf.layers.dropout(layer, rate=0.25)\n",
    "    layer = tf.nn.relu(layer)\n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFlattenLayer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    # layer_shape is assumed to be in shape [number_of_images, image_height, image_width, channels]\n",
    "    # The channels will be the number of fiter_count in the previous layer\n",
    "    feature_count = layer_shape[1:4].num_elements()\n",
    "    # layer_shape[1:4].num_elements()\n",
    "    flat_layer = tf.reshape(layer, [-1, feature_count])\n",
    "    return flat_layer, feature_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFullyConnectedLayer(input_data, input_feature_count, output_feature_count, apply_relu=False):\n",
    "    weights = weight_variable(shape=[input_feature_count, output_feature_count])\n",
    "    bias = bias_variable(length=output_feature_count)\n",
    "    layer = tf.matmul(input_data, weights) + bias\n",
    "    if apply_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitFilenameAndAngle(row):\n",
    "    filename_and_angle = row.strip().split(',')[0].split()\n",
    "    result = [filename_and_angle[0], (float(filename_and_angle[1]) * math.pi) / 180]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataSetInfo(dataset_id='01'):\n",
    "    info_data = ''\n",
    "    info_data_dict = {}\n",
    "    dataset_path = os.path.join('data', 'dataset_' + dataset_id)\n",
    "    info_file_path = os.path.join(dataset_path, 'data.txt')\n",
    "    xs = []\n",
    "    ys = []\n",
    "    with open(info_file_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            filename_and_angle = line.strip().split(',')[0].split()\n",
    "            x, y = filename_and_angle[0], (float(filename_and_angle[1]) * math.pi) / 180\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "    \n",
    "    together = list(zip(xs, ys))\n",
    "    \n",
    "    random.shuffle(together)\n",
    "    filenames, angles = zip(*together)\n",
    "    \n",
    "    info_data_dict['path'] = dataset_path\n",
    "    info_data_dict['filenames'] = filenames\n",
    "    info_data_dict['angles'] = angles\n",
    "    return info_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImages(dataset_info, limit=10000, batch_size=4):\n",
    "    image_data_list = []\n",
    "    rotation_data_list = []\n",
    "    for index, filename in enumerate(dataset_info['filenames']):\n",
    "        image_path = os.path.join(data_info['path'], 'images', filename)\n",
    "        image_data = cv2.imread(image_path)\n",
    "        image_data = cv2.resize(image_data, (0,0), fx=0.4, fy=0.4)\n",
    "        image_data_list.append(image_data)\n",
    "        rotation_data_list.append(dataset_info['angles'][index])\n",
    "        if len(image_data_list) == batch_size:\n",
    "            if batch_size == 1:\n",
    "                image_data_list, rotation_data_list = image_data_list[0], rotation_data_list[0]\n",
    "            yield np.array(image_data_list), np.array(rotation_data_list).reshape(-1, 1)\n",
    "            image_data_list = []\n",
    "            rotation_data_list = []\n",
    "        \n",
    "    if image_data_list:\n",
    "        yield np.array(image_data_list), np.array(rotation_data_list).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData(x):\n",
    "    mu = np.mean(x, axis=(0, 1, 2), keepdims=1)\n",
    "    sigma = np.std(x, axis=(0, 1, 2), keepdims=1)\n",
    "    x = x - mu\n",
    "    x = x / sigma\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = readDataSetInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = None\n",
    "b = None\n",
    "for x, y in readImages(data_info):\n",
    "    a = preprocessData(x)\n",
    "    b = y\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image, sample_rotation = readImages(data_info, batch_size=1).next()\n",
    "# plt.imshow(a[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = sample_image.shape[0]\n",
    "image_width = sample_image.shape[1]\n",
    "image_depth = sample_image.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height * image_width * image_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_size_2 = 2\n",
    "filter_size_3 = 3\n",
    "filter_size_5 = 5\n",
    "filter_count_24 = 24\n",
    "filter_count_32 = 32\n",
    "filter_count_36 = 36\n",
    "filter_count_48 = 48\n",
    "filter_count_64 = 64\n",
    "filter_count_128 = 128\n",
    "\n",
    "fully_conn_layer_1_out_size = 100\n",
    "fully_conn_layer_2_out_size = 50\n",
    "fully_conn_layer_3_out_size = 10\n",
    "fully_conn_layer_4_out_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, image_height, image_width, image_depth])\n",
    "y_actual = tf.placeholder(tf.float32, shape=(None, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_1, conv_weights_1 = createConvulationalLayer(input_data=x,\n",
    "                   channel_count=image_depth,\n",
    "                   filter_size=filter_size_5,\n",
    "                   filter_count=filter_count_24,\n",
    "                   max_pooling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_2, conv_weights_2 = createConvulationalLayer(input_data=conv_layer_1,\n",
    "                   channel_count=filter_count_24,\n",
    "                   filter_size=filter_size_5,\n",
    "                   filter_count=filter_count_36,\n",
    "                   max_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_3, conv_weights_3 = createConvulationalLayer(input_data=conv_layer_2,\n",
    "                   channel_count=filter_count_36,\n",
    "                   filter_size=filter_size_5,\n",
    "                   filter_count=filter_count_48,\n",
    "                   max_pooling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_4, conv_weights_4 = createConvulationalLayer(input_data=conv_layer_3,\n",
    "                   channel_count=filter_count_48,\n",
    "                   filter_size=filter_size_3,\n",
    "                   filter_count=filter_count_64,\n",
    "                   max_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_5, conv_weights_5 = createConvulationalLayer(input_data=conv_layer_4,\n",
    "                   channel_count=filter_count_64,\n",
    "                   filter_size=filter_size_3,\n",
    "                   filter_count=filter_count_64,\n",
    "                   max_pooling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_layer, num_features = createFlattenLayer(conv_layer_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_con_layer_1 = createFullyConnectedLayer(input_data=flat_layer,\n",
    "                         input_feature_count=num_features,\n",
    "                         output_feature_count=fully_conn_layer_1_out_size,\n",
    "                         apply_relu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_con_layer_2 = createFullyConnectedLayer(input_data=fully_con_layer_1,\n",
    "                         input_feature_count=fully_conn_layer_1_out_size,\n",
    "                         output_feature_count=fully_conn_layer_2_out_size,\n",
    "                         apply_relu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_con_layer_3 = createFullyConnectedLayer(input_data=fully_con_layer_2,\n",
    "                         input_feature_count=fully_conn_layer_2_out_size,\n",
    "                         output_feature_count=fully_conn_layer_3_out_size,\n",
    "                         apply_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_con_layer_4 = createFullyConnectedLayer(input_data=fully_con_layer_3,\n",
    "                         input_feature_count=fully_conn_layer_3_out_size,\n",
    "                         output_feature_count=fully_conn_layer_4_out_size,\n",
    "                         apply_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = fully_con_layer_4 # tf.nn.softmax(fully_con_layer_4)\n",
    "cross_entropy = tf.reduce_mean(tf.square(tf.subtract(y_actual, y_predicted)))\n",
    "# cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_actual * tf.log(y_predicted), reduction_indices=[1]))\n",
    "optimizer = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = tf.equal(tf.argmax(y_predicted, 1), tf.argmax(y_actual, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "session = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "\n",
    "highest_test_accuracy = 0\n",
    "highest_train_accuracy = 0\n",
    "train_ac, test_ac = 0, 0\n",
    "training_done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(fig, ax, entropy):    \n",
    "    ax.clear()\n",
    "    ax.plot(entropy)\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "\n",
    "fig.show()\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "entropy = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    if training_done:\n",
    "        break\n",
    "    for batch_X, batch_Y in readImages(data_info):\n",
    "        batch_X = preprocessData(batch_X)\n",
    "        train_data = {x: batch_X, y_actual: batch_Y}\n",
    "        \n",
    "        # Training Step\n",
    "        session.run(optimizer, feed_dict=train_data)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        entropy_value = session.run(cross_entropy, feed_dict=train_data)\n",
    "        if not np.isnan(entropy_value):\n",
    "            entropy.append(entropy_value)\n",
    "            draw(fig, ax, entropy)\n",
    "        \n",
    "print(\"Training done in %f mins\"%((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = os.path.join(os.getcwd(), 'model')\n",
    "if not os.path.exists(model):\n",
    "    os.makedirs(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if raw_input('Do you want to save this model ? (y/n)').strip() == 'y':\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(session, os.path.join(model, \"model.ckpt\"))\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
